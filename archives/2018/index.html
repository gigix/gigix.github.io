<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    

    <title>
        归档: 2018
    </title>

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    
    <meta name="author" content="Jeff Xiong">
    
    

    <meta property="og:type" content="website">
<meta property="og:title" content="归档: 2018">
<meta property="og:url" content="http://gigix.thoughtworkers.org/archives/2018/index.html">
<meta property="og:site_name" content="透明思考">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="归档: 2018">

    
    <link rel="alternate" href="/atom.xml" title="透明思考" type="application/atom+xml">
    
    
    <link rel="icon" type="image/x-icon" href="/favicon.png">
    
    <link rel="stylesheet" href="/css/uno.css">

    <script src="/js/jquery.min.js"></script>

</head>
<body>

    <span class="mobile btn-mobile-menu">
        <i class="icon icon-list btn-mobile-menu__icon"></i>
        <i class="icon icon-x-circle btn-mobile-close__icon hidden"></i>
    </span>

    
<header class="panel-cover panel-cover--collapsed">

  <div class="panel-main">

    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        

        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage">透明思考</a></h1>

        <hr class="panel-cover__divider" />
        <p class="panel-cover__description">
          Transparent Thoughts
        </p>
        <hr class="panel-cover__divider panel-cover__divider--secondary" />

        <div class="navigation-wrapper">

          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">

              
                
                <li class="navigation__item"><a href="/#blog" title="" class="blog-button">Blog</a></li>
              

            </ul>
          </nav>

          <!-- ----------------------------
To add a new social icon simply duplicate one of the list items from below
and change the class in the <i> tag to match the desired social network
and then add your link to the <a>. Here is a full list of social network
classes that you can use:

    icon-social-500px
    icon-social-behance
    icon-social-delicious
    icon-social-designer-news
    icon-social-deviant-art
    icon-social-digg
    icon-social-dribbble
    icon-social-facebook
    icon-social-flickr
    icon-social-forrst
    icon-social-foursquare
    icon-social-github
    icon-social-google-plus
    icon-social-hi5
    icon-social-instagram
    icon-social-lastfm
    icon-social-linkedin
    icon-social-medium
    icon-social-myspace
    icon-social-path
    icon-social-pinterest
    icon-social-rdio
    icon-social-reddit
    icon-social-skype
    icon-social-spotify
    icon-social-stack-overflow
    icon-social-steam
    icon-social-stumbleupon
    icon-social-treehouse
    icon-social-tumblr
    icon-social-twitter
    icon-social-vimeo
    icon-social-xbox
    icon-social-yelp
    icon-social-youtube
    icon-social-zerply
    icon-mail

------------------------------ -->

<nav class="cover-navigation navigation--social">
  <ul class="navigation">


  <!-- Github -->
  <li class="navigation__item">
    <a href="https://github.com/gigix" title="Gigix on GitHub" target="_blank">
      <i class='icon icon-social-github'></i>
      <span class="label">GitHub</span>
    </a>
  </li>

  </ul>
</nav>

          <script>
    function doSearch() {
        var keyword = $('#keyword').val();
        if (keyword.trim() === '') {
            window.location.href = 'http://gigix.thoughtworkers.org/#blog';
        } else {
            window.open('http://www.google.com/search?q=site:gigix.thoughtworkers.org+' + keyword);
        }
    }
</script>

<div class="search">
    <input id="keyword" type="text"/>
    <input type="button" value="Search" class="btn" onclick="doSearch()"/>
</div>


        </div>

      </div>

    </div>

    <div class="panel-cover--overlay"></div>
  </div>
</header>

    <div class="content-wrapper">
        <div class="content-wrapper__inner entry">
            


  <h1 class="archive-title">归档: 2018</h1>
  <hr class="post-list__divider" />


<div class="main-post-list">
    <ol class="post-list">
    
    
    <li class="post">

      <h2 class="post-list__post-title post-title"><a href="/2018/2/17/precise-deliverying/" title="link to 精准投放的原理及其担忧">精准投放的原理及其担忧</a></h2>

      <p class="excerpt">
        <p>从WWW网站发源之初，网站的经营者们就清楚地认识到，自己经营的是一份媒体，就跟报刊杂志一样。媒体的收入，第一是来自读者付费，第二也是更主要的，是来自广告。于是站长们在自己的网站页面上开辟出或大或小、或纵或横的广告位，广告主则可以采购广告位。据笔者亲眼所见，迟至2001年，中国很多网站的广告销售方式仍然是由销售人员拿着一份打印出来的“刊例”（这个词也同样是来自报刊出版领域），直接向广告主介绍。购买广告位的方式，也通常是一家广告主承包一个广告位一段时间（通常是几天，有时长达几周），只有在最热门的广告位（例如首页顶部Banner）才有简单的轮换机制。广告收费是按照广告位与放置时长计算，网站几乎不向广告主反馈投放的效果。简而言之，这是在线广告的初创阶段，网站基本上是被当做报刊来经营的。</p>
<p>这种投放方式显然是很原始的，最大的问题有两个：首先，广告主需要自己接洽多家媒体，分配各家媒体的投放预算，媒体则要自己管理多家广告主的投放排期，这对于广告主和媒体都是个很大的工作量；而且，广告投放出去以后效果如何，哪些媒体效果更好，后续投放应该如何调整，这些信息广告主无法获得，即使媒体有回馈数据，其中有多大成分的数据夸大，广告主也无从知晓。在这两个痛点的催生下，就出现了“媒体采买平台”的服务形式：经营这个平台的广告代理公司向大量媒体（即网站）购买广告位，广告主只要把广告投放到这一家代理公司，代理公司自会通过软件程序把广告派发到媒体。如此一来，广告主和媒体不用彼此一对一接洽，工作量都减少很多。并且在这个阶段，广告收费模式也改为按点击付费（通常会承诺一定浏览流量），广告主可以更准确地知道广告的效果，按实际效果付费。</p>
<p>在媒体采买平台的基础上，相关的技术与业态又不断升级，逐渐形成了广告交易平台（ADvertisement eXchange，ADX）、供给方平台（Supply Side Platform，SSP）和需求方平台（Demand Side Platform，DSP）三大类平台协作的格局。供给方平台（SSP）为媒体服务，它负责汇集媒体广告位资源，尽量把广告位卖出最高价；需求方平台（DSP）为广告主服务，它负责汇集广告投放诉求，尽量以最低价格投放达到最佳效果；广告交易平台（ADX）则保持中立态度，为供需两方撮合交易，就像股市一样：只要有一个最高买价能匹配到一个符合条件的最低卖价，就会完成一次广告交易，DSP就会向SSP进行一次投放。</p>
<p>IT技术创造的奇迹在于，这一系列看似复杂的竞价采购、交易撮合，可以在极短的时间内完成，因此交易的单元可以极小、交易量可以极大。在ADX发生的一次交易，标的物通常是“一次投放”，或者说是“一次浏览”。当你轻点鼠标，打开一个网页时，这个页面上的几个、十几个广告位就分别被SSP发送给ADX“叫卖”，匹配到出价最高的DSP“卖主”，然后把广告呈现在你面前。这整个投放决策的过程，业界标准要求在0.4秒以内完成。</p>
<p>由于广告投放已经被细化到按次采购，于是广告位本身是否热门变得不再重要，竞价采购的对象变成了流量本身。当然，即使在网站发展初期、甚至在报刊杂志上，广告主和广告代理也会选择流量。例如雷克萨斯不会选择在城市晚报上投广告，而是会更多地在时尚杂志和飞机杂志上出现，这就是对“流量”（也即读者）做过筛选的结果。在这个例子里，丰田公司（或者其广告代理）从媒体属性上对读者的身份、职业、收入水平（统称为“流量属性”）有一个大致的推测，基于这个推测做了投放决定。然而受限于纸媒的技术特质，这个投放决定是非常粗糙的：第一，它能够获得的流量属性信息非常有限；第二，它只能对相当大的人群、在相当长的时间段上做决定；第三，它能得到的效果反馈非常少。</p>
<p>而程序化的广告投放则完全克服了这三个局限：投放决定是基于每一次浏览、每一个流量来做出的；投放效果（有多大比例的用户点击广告）可以当天回馈给广告主；最重要的是，在线广告业务的经营者能够获得空前丰富的关于“流量”的信息。比如说，当你在微信中点开一个带广告的页面，DSP就有可能获得下列关于你的信息：</p>
<ul>
<li>你是谁：你的微信ID，你的手机号，你的性别、生日、星座、身高、体重、血型……</li>
<li>你是个什么样的人：你的收入，你的生活方式，你的价值观世界观，你的意识形态，你的观点态度……</li>
<li>你做哪些事：你上网看什么内容，你喜欢什么品牌，你买什么东西、在哪里买，你跟谁交朋友……</li>
<li>你身边的环境：你在什么地方，你周围在发生什么，你在什么时间上网，你在乘坐地铁、公交车、还是滴滴专车……</li>
</ul>
<p>在线广告行业里把这些信息都称为“标签”，DSP就是基于这些标签来判断，现在点开网页的这个流量值多少钱，并在0.4秒内决定是否要投标竞价。所以当你听到“流量经济”、“流量就是钱”这样的说法，你应该意识到：这说的就是字面上的意思，每次浏览、每个流量都是有价的。</p>
<p>也许你会怀疑，DSP怎么会知道我这么多信息？笔者可以透露，上面列举的这些标签，都是一个真实的IT系统中已经存在的标签，实际上DSP能获得的信息比这个列表只多不少。而且DSP非常有意愿知道更多流量属性，因此又衍生出了“数据管理平台”（Data Management Platform，DMP）。这些平台专门从各种来源收集与用户相关的信息，并把这些信息汇集起来形成“统一客户视图”（Single Customer View）——也就是给这个用户、这个流量贴上更加丰富的标签。</p>
<p>举个例子来说明DMP的工作方式。当你在机场连上免费WIFI，你会看到一个登录页面，你输入手机号获得验证码，连上网络，这时WIFI热点背后的程序已经知道你的手机号、你用的手机款式、你所在的地点，这些信息马上被发送给一个DMP。这时你的朋友从微信发给你一篇文章，是介绍大明星的座驾，你细细欣赏了贝克汉姆的腹肌和他的奔驰G系越野车，于是这个网页背后的埋点程序知道了你对汽车品牌的偏好，这个信息和你的微信ID一起也被发送给一个DMP——很可能是同一个DMP。看完文章，你打开购物软件，买了几样水果送到家里，于是电商平台知道了你的消费能力和居住的小区，这些信息和你的手机号一起同样被发送给DMP。通过手机号、微信ID、身份证号……这些唯一身份标识，DMP建立起了关于你的统一顾客视图，可能会给你贴上成百上千个标签。</p>
<p>基于这些标签，DSP就可以展开非常精确的广告投放。例如对于奔驰投放的Banner广告，DSP可能会优先考虑这样一些标签：30~40岁，年收入40~60万，居住在一二线城市，本科以上学历，从事IT、金融、房地产等职业，现在车龄6年以上，近期流露换车意向……一旦高度符合这些标签的流量出现，DSP就会高价拍下广告位。一些技术领先的DSP已经开始使用机器学习技术，不用人手挑选投放目标标签，而是由人工智能自动识别目标流量，使广告投放更加精准。</p>
<p>然后，当你开始跟老婆讨论是不是该换台新车的时候，你无意间发现，手机上打开的网页里有一辆漂亮的奔驰C200休旅车，你点开广告链接，跟老婆一起左看右看，觉得这辆车既有面子又实惠，跟你家的风格简直是天作之合，于是你开心地按下了“预约试驾”。你大概不会多想，这个广告出现的时机怎么那么恰到好处。最终你买下了这辆车，就好像这完全是你自己的决定一样——就在你快要付款的一刻，你又瞥见手机网银的界面上有一个刷信用卡买车免息分期的活动，多巧呀。</p>
<p>既然广告可以定制，有什么道理媒体上呈现的内容本身不能被定制呢？感兴趣的话，你可以自己做一个实验：首先看看你的知乎首页上有哪些内容，一般来说不会出现跟火影忍者相关的问答，毕竟火影大结局也有段日子了；然后下载腾讯动漫，每天看上几十话火影，用不了几天，你的知乎首页上就会出现一堆讨论鸣人和佐助的帖子。笔者亲身观察到这个现象，好奇地搜索知乎的投资方，腾讯果然在列。大胆猜测一下，知乎即使不是直接使用腾讯的DMP“广点通”，技术原理也相去不远。既然都看见“小樱的实力能到影级吗”这么有吸引力的帖子，怎么能不打开看看呢？于是现在笔者的知乎首页上，各种忍术已经连绵不绝了。</p>
<p>内容定制正在成为数字化营销的主流工具。和纸媒不同，数字化产品的每次打开、每次浏览都可以是动态的、个性化的。DMP已经掌握了如此丰富的用户洞察，媒体没有道理继续保持一成不变的内容呈现，一定会利用DMP的数据来达成更高的转化率——可能是转化为购车的消费者，也可能是转化为支持某个政策的变革、某种意识形态的观点。于是我们看到，像今日头条这样的媒体，呈现内容的原则不是“外面在发生什么”，而是“读者喜欢看什么”——当然纸媒也有过度迎合读者的风险，但纸媒毕竟只能面向大群读者做一个粗糙的推测，而互联网媒体（和社交网络）则在技术的推动下形成了一个完美的、牢不可破的回音壁。至于传统意义上媒体要客观中立地展现世界样貌的职责，在转化率这个KPI的驱动下显得有些苍白无力。</p>
<p>精准投放可能带来什么危害呢？数据科学家Cathy O’Neil在《<a href="https://book.douban.com/subject/26785866/" target="_blank" rel="external">数学大杀器</a>》（Weapons of Math Destruction）一书中介绍了一些已经现实发生的场景。其一，基于数据的精准投放如果被用于教育、医疗、保险等与生活休戚相关的“商品”上，就可能造成对特定人群、尤其是弱势人群的歧视和损害。在美国，有一些质量低劣的教育机构，把自己的广告定向投放到收入低、教育程度低、并且新近遭遇人生重大打击的人群——例如刚离婚、或刚被解雇。这样的人群、处于这样的心理状态下，更容易被这些心灵鸡汤式的广告吸引，从自己原本就已经拮据的经济中再拿出一笔不菲的资金，来参加一个对自身能力没有提升、也不被人才市场承认的培训计划。在中国我们也看到，尽管百度宣称其中立性，但莆田系在百度上投放的医疗广告同样精准地找到了教育程度较低、经济状况较差、已经饱受疾病损害的那些弱势家庭。</p>
<p>另一方面，当精准投放被应用于政治目的，它能够强化大型利益团体对群众观点和政治议程的操控。2011年奥巴马的竞选团队与IT咨询公司埃森哲合作，首次在美国总统选举中引入了大数据和精准投放技术。在2015年的大选中，“共和党犹太人联盟”的领导者们在拉斯维加斯的威尼斯人酒店开会，在酒店上网时他们看到候选人泰德·克鲁兹承诺加大对以色列安全支持力度的广告宣传。他们不知道的是，这条广告只在这家酒店、只在他们开会的这几天播放。当政治家和利益团体可以不必保持连贯统一的公众形象、而是可以针对受众“定制”其形象和政治观点，这种变化究竟会给公共生活带来什么影响，可能答案还并不清晰。</p>
<p>在《数学大杀器》中，O’Neil提出了一些限制大企业过度利用个人数据的途径，例如效仿欧洲对互联网数据的管制模式：只有在用户明确同意的情况下，企业才能采集用户数据，且采集到的数据不能用于其他用途。“明确同意”的规定，可能仍然容易通过隐晦的用户协议等方式来绕过；但“不作它用”的规定，对于数据滥用是一个很好的预防措施。至于国内的相关管制会在何时、以何种形式出现，目前仍是未知。在可见的将来，恐怕我们还得继续享受互联网提供给我们的精准得有点细思极恐的广告和内容。</p>

      </p>

      <div class="post-list__meta">

        <time datetime="2月 17 2018" class="post-list__meta--date date">2月 17 2018</time> &#8226; 

        <span class="post-list__meta--tags tags">
          <font class="categories">
            
          </font>
          

        </span>
      </div>

      <hr class="post-list__divider" />
    </li>
    
    <li class="post">

      <h2 class="post-list__post-title post-title"><a href="/2018/1/28/machine-learning-for-managers/" title="link to 机器学习项目如何管理：设置期望">机器学习项目如何管理：设置期望</a></h2>

      <p class="excerpt">
        <p>我在之前的一篇文章中提到，<a href="/2017/12/12/ml-project-management-current-situation/">机器学习项目如何管理</a>，目前在行业内是一个普遍存在的难题。具体而言，对于这类项目，我们需要一套行之有效的工作办法，帮助一线工作者：(1)知道什么时候该做什么事；(2)知道什么时候该看什么指标；(3)知道什么时候可能有什么风险。这样一套工作办法的第一步，就是对一个机器学习项目设置合理的期望。</p>
<h2 id="机器学习到底是在做什么"><a href="#机器学习到底是在做什么" class="headerlink" title="机器学习到底是在做什么"></a>机器学习到底是在做什么</h2><p>机器学习的基本过程可以用下面这张图来呈现：</p>
<p><img src="/assets/2018/1/28/ml-process.png"></p>
<p>拿到已有的历史数据作为训练数据，我们需要对训练数据进行<strong>矢量化</strong>处理，把输入的不论什么形态的数据（例如文本、音频、图片、棋盘盘面）都转化成包含若干列的矢量。从矢量中我们再分出<strong>特征</strong>（X）和结果（Y），通常特征的列数远多于结果。</p>
<p>我们把X部分交给一个<strong>模型</strong>，算出与每一行训练数据对应的预测值Y’。所谓模型，就是一系列的权重系数，把这些权重系数用在一行输入数据上，就会得到针对这一行输入数据的结果预测。我们把Y’与Y对比，评判这一轮预测的效果。这个效果，我们用<strong>损失</strong>来度量。</p>
<p>然后我们用一个机器学习<strong>算法</strong>来尝试优化损失。所谓优化，就是不断尝试调整模型中的权重参数。调一次，再计算出一组新的Y’，再与Y比较效果。如此迭代，直到损失不再降低，或者达到预设的迭代次数。</p>
<p>所以，首先必须要记住：机器学习是一种优化任务。优化任务的目标不是找到“正确”的答案，而是找到一个“看起来不错”的答案。这一点会对我们看待这类项目的方式产生深远的影响。</p>
<h2 id="如何为优化任务设置期望"><a href="#如何为优化任务设置期望" class="headerlink" title="如何为优化任务设置期望"></a>如何为优化任务设置期望</h2><p>传统意义上的软件开发（例如开发一个电商网站、开发一个社交app）是能够得到确定结果的：只要需求分析得够细致、原型设计得够保真、测试进行得够周全，你就可以准确地框定一个软件开发过程的产出结果，点击哪个按钮得到什么效果都是可以预先定义的。而机器学习项目则不然：不论分类、回归、聚类，本质上都是对某个损失函数迭代优化的过程。它没有唯一正确的答案，只是有希望得到看起来不错的答案。优化任务的逻辑不是因果，而是概率。</p>
<p>对于优化任务，我们不能问“是否正确”这个问题。有意义的问题是，模型的预测准确率能达到多少。一个缺乏经验的管理者可能会说“越高越好”，或者拍脑袋说出一个数字“90%”，显然这都不太有助于合理地管理期望和把控进展。暂时放下“准确率”的定义不谈，我们如何知道对于一个机器学习得出的模型应该期望什么样的准确率呢？显然大多数情况下预测准确率不可能达到100%，那么这个期望应该如何设置？</p>
<p>我们需要引入一个概念：<a href="https://en.wikipedia.org/wiki/Bayes_error_rate" target="_blank" rel="external">贝叶斯错误率</a>。简单说，贝叶斯错误率是对于一个问题有可能达到的最好的预测效果。贝叶斯错误率通常不是那么容易直接获得的，所以我们用人类的判断作为一个代理指标：一般来说，我们认为人类的判断错误率高于贝叶斯错误率，但是也相差不大。于是前面的问题变成了：对于一个机器学习得到的模型，我们期望它的预测准确率与人类的判断相比如何？</p>
<p>这个问题没有唯一正确的答案。有些时候我们希望模型的准确率高于、甚至远高于人类的判断；另一些时候，我们只需要模型的准确率勉强接近人类的判断，这样的模型就可以帮人类完成大量繁琐的工作量。对模型的期望设置不是一个技术问题，而是一个业务问题，在开始一个机器学习项目之前，就需要先与业务的负责人展开相关的对话。</p>
<h2 id="如何定义“准确”"><a href="#如何定义“准确”" class="headerlink" title="如何定义“准确”"></a>如何定义“准确”</h2><p>仍然以最简单的分类问题为例，模型的判别分为阳性（positive）和阴性（negative）两种，两种判别都有正确和错误的可能，于是总共就有了四种可能的情况：</p>
<ul>
<li>True Positive（TP）：判别为阳性，实际也是阳性</li>
<li>False Positive（FP）：判别为阳性，实际却是阴性</li>
<li>True Negative（TN）：判别为阴性，实际也是阴性</li>
<li>False Negative（FN）：判别为阴性，实际却是阳性</li>
</ul>
<p>一种朴素的“准确率”定义方法是“判别正确的比例”，即：</p>
<p><img src="/assets/2018/1/28/accuracy.png"></p>
<p>但是当样本的分布极其不均衡时，这个对准确率的定义会很有误导性。例如我们假设10000人里有150人患胃癌（阳性），经过对血样的分析，一个模型识别出100名患者（TP），有50名患者没有发现（FN），同时误报了另外没有患病的150人（FP）；另一个模型则不做任何判断，直接宣称所有人都没有胃癌。我们直觉会认为前一个模型优于后一个，但朴素的准确率定义却给了我们相反的结论：</p>
<p><img src="/assets/2018/1/28/accuracy-paradox.png"></p>
<p>因为<a href="https://en.wikipedia.org/wiki/Accuracy_paradox" target="_blank" rel="external">朴素的准确率定义有这样的问题</a>，实践中更常用的指标是“精确率”（Precision）和“召回率”（Recall）。它们的定义分别是：</p>
<ul>
<li>Precision = TP/(TP+FP)：在预测的阳性个例中，有多少是预测正确的？</li>
<li>Recall = TP/(TP+FN)：在所有的阳性个例中，总共找出了多少？</li>
</ul>
<p><img src="/assets/2018/1/28/precision-recall.png"></p>
<p>可以看出，Precision和Recall往往是互相矛盾的：如果追求找出更多阳性个例（提高Recall），那么阴性个例被误判为阳性的情况也会增加（降低Precision），反之亦然。在不同的业务场景下，需要追求的指标也会不同。例如在前面的体检场景下，我们会追求更高的Recall：尽量找出所有患病的人，有一些人被误报也没关系。而另一个极端场景是推荐顾客可能会卖的商品，这时我们会追求更高的Precision：推荐位只有5个，我们必须保证推荐的每一件商品都打中用户的兴趣点，至于还有几千个他可能感兴趣的商品没有被推荐，那并不重要。</p>
<p>以上我们看到的只是最简单的分类问题的场景。对于其他场景，可能需要引入其他度量准确率的指标。所以我们再次看到，采用什么指标来定义“准确”、应该如何权衡指标的取舍，这同样是一个与场景高度相关的业务问题。项目的管理者和业务代表需要清晰理解指标的含义、并合理设置对指标的期望。</p>
<h2 id="然后呢……"><a href="#然后呢……" class="headerlink" title="然后呢……"></a>然后呢……</h2><p>如果项目的管理者和业务方代表能懂得机器学习是一类优化任务、能理解优化任务的度量方式、能针对这类任务设置合理的期望，在理解和把握项目进度与风险的路上他们就迈出了第一步。在下一篇文章里，我会拆解出机器学习类项目涉及的工作内容。读者将会看到，看起来高大上的机器学习、人工智能，实际上需要特殊技能和高中以上数学能力的只有极小一部分，其他都是普通的、确定性的软件开发工作，可以用典型的软件开发过程和管理方法来对待。针对份额极小、但有时非常重要的“自行训练模型”部分，我会给出更加细化的工作内容拆解，并提出任务拆分、进度管理、风险管理的相关办法。</p>

      </p>

      <div class="post-list__meta">

        <time datetime="1月 28 2018" class="post-list__meta--date date">1月 28 2018</time> &#8226; 

        <span class="post-list__meta--tags tags">
          <font class="categories">
            
          </font>
          

        </span>
      </div>

      <hr class="post-list__divider" />
    </li>
    
    <li class="post">

      <h2 class="post-list__post-title post-title"><a href="/2018/1/13/dps-self-service-data/" title="link to 数字化企业的数据自服务">数字化企业的数据自服务</a></h2>

      <p class="excerpt">
        <p>在<a href="/2017/4/25/ditigal-platform-strategy-intro/">前文</a>中我们说到，传统企业在逐步建设自己的数字平台过程中，需要抓住交付基础设施、API和架构治理、数据自服务、创新实验基础设施和监控体系、用户触点技术这五个支柱。今天我们讨论的主题是“数据自服务”，看看一个倡导消除摩擦、建设生态、推动创新的数字化平台如何处理数据。</p>
<blockquote>
<p><strong>前情回顾</strong></p>
<ul>
<li><a href="/2017/4/25/ditigal-platform-strategy-intro/">什么是数字平台战略</a> </li>
<li><a href="/2017/5/7/dps-delivery-infrastructure/">数字化企业的交付基础设施</a></li>
<li><a href="/2017/5/22/dps-api-architecture-remediation/">数字化企业的API架构治理</a></li>
</ul>
</blockquote>
<h2 id="什么是数据自服务"><a href="#什么是数据自服务" class="headerlink" title="什么是数据自服务"></a>什么是数据自服务</h2><p>数据在企业中的处理过程，能清晰地映射出<a href="http://www.melconway.com/Home/Conways_Law.html" target="_blank" rel="external">康威定律</a>对IT系统的影响。在各个部门分别建设IT系统、组织内部大量存在信息筒仓（silo）的年代，数据的操作由OLTP应用系统的开发团队同步开发，那时几乎每个政府信息化、企业信息化系统都会有一块“报表需求”。随后众多组织认识到筒仓系统导致信息在组织内不能拉通，不能产生对整体业务流程的洞察，于是开始建设以数据仓库为代表的OLAP系统。</p>
<p>这些系统在支撑更高级、更复杂的数据分析的同时，也对应地在组织中造就了一支专业的“数据团队”。这些人使用非常专业的技术和工具对数据进行提取、转换、装载、建立数据立方、多维钻取、生成报表。这些专业的技术和工具，普通的软件开发人员并不掌握，因此对数据处理、分析和呈现的变更都必须归集到这个数据团队来完成。结果是，数据团队的backlog里累积了来自各个部门的需求，需求的响应能力下降，IT系统从上线到获得市场洞察的周期变长。</p>
<p>微服务架构鼓励小型的、全功能的团队拥有一个完整的服务（及其对应的业务）。这样的全功能团队不光要开发和运维IT系统，还要能从数据中获得洞察——而且要快，不然就会跟不上市场变化，甚至使一些重要的业务场景无法得到支撑。因此他们不能坐等一支集中式的、缓慢的数据团队来响应他们的需求，他们需要数据自服务能力。</p>
<p>要赋能数据自服务，企业的数字化平台要考虑“两个披萨团队”的下列诉求：</p>
<ul>
<li>需要定义<strong>数据流水线</strong>，使数据能够顺畅地流过收集、转换、存储、探索/预测、可视化等阶段，产生业务价值。</li>
<li>需要用<strong>实时的架构和API</strong>在短时间内处理大量、非结构化的数据，从中获得洞见，并实时影响决策。</li>
<li>为了提高应变能力，系统中的数据不做ETL预处理，而是以“生数据”的形式首先存入<strong>数据湖</strong>，等有了具体的问题要回答时，再去组织和筛选数据，从中找出答案。</li>
<li>更进一步把数据包装成能供外人使用的<strong>数据产品</strong>，让第三方从数据中获得新的洞见与价值。</li>
<li>为了支持数据产品的运营，需要实现<strong>细粒度授权</strong>，针对不同的用户身份，授权访问不同范围的数据。</li>
</ul>
<h2 id="数据自服务解读"><a href="#数据自服务解读" class="headerlink" title="数据自服务解读"></a>数据自服务解读</h2><p>下面是ThoughtWorks的<a href="https://www.thoughtworks.com/digital-platform-strategy" target="_blank" rel="external">数字平台战略</a>第三个支柱“数据自服务”中所蕴涵的具体内容。</p>
<p><img src="/assets/2017/6/13/self-service-data.jpg"></p>
<h3 id="数据流水线设计"><a href="#数据流水线设计" class="headerlink" title="数据流水线设计"></a>数据流水线设计</h3><p>所谓流水线，是指用大数据创造价值的整个数据流。流水线从数据采集开始，随后是数据的清洗或过滤，再然后是将数据结构化到存储仓库中以便访问和查询，这之后就可以通过探索或预测的方式从数据中找到业务问题的答案，并可视化呈现出来。</p>
<p><img src="/assets/2017/6/13/data-pipeline.jpg"></p>
<p>一条运转良好的数据流水线，能有效处理移动/物联网等新技术制造出的极其大量的数据，缩短数据从获取到产生洞见的反馈周期，并以开发者友好的方式完成数据各个环节的处理，赋能一体化团队。</p>
<p>数据流水线的实现有两种可能的方式。一种方式是在各个环节采用各种特定的工具，例如<a href="https://www.thoughtworks.com/insights/blog/scala-symposium-big-data-pipeline-powered-scala" target="_blank" rel="external">前面介绍的数据流水线</a>，各个环节都可以用开源的工具来实现。当然，<a href="http://www.techrepublic.com/article/manage-complex-big-data-pipeline-challenges-with-these-approaches/" target="_blank" rel="external">选择这种方式也并非没有挑战</a>：组织必须自己编写和维护“胶水代码”，把各种专用工具组合成一个内聚的整体。对组织的技术能力有较高的要求。</p>
<p><img src="/assets/2017/6/13/data-pipeline-impl.jpg"></p>
<p>除了基于开源软件实现自己的数据流水线，也可以考虑采用云上的数据流水线PaaS服务，例如<a href="https://databricks.com/" target="_blank" rel="external">Databricks</a>、<a href="http://docs.aws.amazon.com/datapipeline/latest/DeveloperGuide/what-is-datapipeline.html" target="_blank" rel="external">AWS Data Pipeline</a>、<a href="https://docs.microsoft.com/en-us/azure/data-factory/data-factory-introduction" target="_blank" rel="external">Azure Data Factory</a>等。这个方式的优点是对技术能力要求较低，缺点则是造成对特定云平台/PaaS提供商的依赖。</p>
<h3 id="实时架构和API"><a href="#实时架构和API" class="headerlink" title="实时架构和API"></a>实时架构和API</h3><p>实时的数据架构和API支持短时间内处理大量、非结构化的数据，从中获得洞见，并“实时”影响决策。正如<a href="http://www.oreilly.com/data/free/files/big-data-analytics.pdf" target="_blank" rel="external">Mike Barlow所说</a>：“这是关于在正确时间做出更好决定并采取行动的能力，例如在顾客刷卡的时候识别信用卡欺诈，或者当顾客在排队结账的时候给个优惠，或者当用户在阅读某篇文章的时候推送某个广告。”</p>
<p>在<a href="http://blog.cloudera.com/blog/2015/06/architectural-patterns-for-near-real-time-data-processing-with-apache-hadoop/" target="_blank" rel="external">Cloudera的一篇文章</a>中介绍了实时数据处理的4个架构模式，整个流水线架构在Flume/Kafka基础上：</p>
<ul>
<li>数据流吸收：低延迟将事件持久化到HDFS、HBase、Solr等存储机制</li>
<li>近实时（100毫秒以下）的事件处理：数据到达时立即采取警告、标记、转换、过滤等初步行动</li>
<li>近实时的事件分片处理：与前一个模式类似，但是先对数据分片</li>
<li>复杂而灵活的聚合或机器学习拓扑，使用Spark</li>
</ul>
<h3 id="数据湖设计"><a href="#数据湖设计" class="headerlink" title="数据湖设计"></a>数据湖设计</h3><p>数据湖概念最初提出是在<a href="https://www.forbes.com/sites/edddumbill/2014/01/14/the-data-lake-dream/#28439a1869c0" target="_blank" rel="external">2014年Forbes的一篇文章</a>中。它的概念是：不对数据做提前的“优化”处理，而是直接把生数据存储在容易获得的、便宜的存储环境中；等有了具体的问题要回答时，再去组织和筛选数据，从中找出答案。按照<a href="https://www.thoughtworks.com/radar/techniques/data-lake" target="_blank" rel="external">ThoughtWorks技术雷达的定义</a>，数据湖中的数据应该是不可修改（immutable）的。</p>
<p>数据湖试图解决数据仓库几方面的问题：</p>
<ul>
<li>预先的ETL处理终归会损失信息，如果事后才发现需要生数据中的某些信息、但是这些信息又没有通过ETL进入数据仓库，那么信息就无法寻回了。</li>
<li>ETL的编写相当麻烦。数据仓库的schema发生改变，ETL也要跟着改变；应用程序的schema发生改变，ETL也要跟着改变。因此数据仓库通常由一个单独的团队负责，于是形成一个function team，响应速度慢。</li>
<li>数据仓库的分析需要专门的技能，大部分应用程序开发者不掌握，再度强化了数据仓库专门团队；而数据仓库团队其实离业务很远，并不能快速准确地响应业务对数据分析的需求。</li>
</ul>
<p>在数据湖概念背后是康威法则的体现：数据能力与业务需求对齐。它要解决的核心问题是专门的数据仓库团队成为响应力瓶颈。当IT能力与业务需求组合形成一体化团队以后，数据的产生方不再假设未来要解决什么问题，因此也不对数据做预处理，只是直接存储生数据；数据的使用方以通用编程语言（例如Java或Python）来操作数据，从而无需依赖专门的、集中式的数据团队。</p>
<p><a href="https://www.forbes.com/sites/edddumbill/2014/01/14/the-data-lake-dream/#28439a1869c0" target="_blank" rel="external">数据湖实施</a>的第一步是把生数据存储在廉价的存储介质（可能是HDFS，也可能是S3，或者FTP等）。对于每份生数据，应该有一份元数据描述其来源、用途、和哪些数据相关等等。元数据允许整个组织查看和搜索，让每个一体化团队能够自助式寻找自己需要的数据。任何团队都可以在生数据的基础上开发自己的微服务，微服务处理之后的数据可以作为另一份生数据回到数据湖。维护数据湖的团队只做很少的基础设施工作，生数据的输入和使用都由与业务强关联的开发团队来进行。传统数据仓库的多维分析、报表等功能同样可以作为一个服务接入数据湖。</p>
<p>在实施数据湖的时候，有一种常见的反模式：企业有了一个名义上的数据湖（例如一个非常大的HDFS），但是数据只进不出，成了“数据泥沼”（或数据墓地）。在这种情况下，尽管数据湖的存储做得很棒，但是组织并没有很好地消化这些数据（可能是因为数据科学家不具备分析生数据的技术能力，而是更习惯于传统的、基于数据仓库的分析方式），从而不能很好地兑现数据湖的价值。</p>
<h3 id="数据即产品"><a href="#数据即产品" class="headerlink" title="数据即产品"></a>数据即产品</h3><p><a href="http://www.juiceanalytics.com/writing/turning-data-into-product" target="_blank" rel="external">数据产品</a>是指将企业已经拥有或能够采集的数据资产，转变成能帮助用户解决具体问题的产品。Forbes列举了<a href="https://www.forbes.com/sites/lutzfinger/2014/08/19/3-data-products-you-need-to-know/#7f497e0566f6" target="_blank" rel="external">几类值得关注的数据产品</a>：</p>
<ul>
<li>用于benchmark的数据</li>
<li>用于推荐系统的数据</li>
<li>用于预测的数据</li>
</ul>
<p><a href="https://datafloq.com/read/simplest-way-monetize-data-product/980" target="_blank" rel="external">数据产品是数据资产变现的快速途径</a>。因为数据产品有几个优势：开发快，不需要开发出完整的模型，只要做好数据整理就可以对外提供；顾客面宽，一份数据可以产生多种用途；数据可以再度加工。数据产品给企业创造的收益既可以是直接的（用户想要访问数据或分析时收费）也可以是间接的（提升顾客忠诚度、节省成本、或增加渠道转化率）。</p>
<p>在实现数据产品的时候，不仅要把数据打包，更重要的是提供数据之间的关联。数据产品的供应者需要提出洞见、指导用户做决策，而不仅仅是提供数据点。数据产品需要考虑用户的场景和体验，并在使用过程中不断演进。</p>
<h3 id="细粒度授权"><a href="#细粒度授权" class="headerlink" title="细粒度授权"></a>细粒度授权</h3><p>当数据以产品或服务的形式对外提供时，企业可能需要针对不同的用户身份，授权访问不同范围的数据，对应不同的服务水平和不同的安全级别。一些典型的细粒度授权的场景可能包括：企业内部和外部用户能够访问的数据范围不同；供应链上不同环节的合作伙伴能够访问的数据范围不同；付费与免费的用户能够访问的数据范围不同；不同会员级别能够访问的数据范围不同；等等。</p>
<p>允许访问的数据范围属于数据产品/服务自身的业务规则。《微服务设计》的第9章建议，“[服务]网关可以提供相当有效的粗粒度的身份验证……不过，比允许（或禁止）的特定资源或端点更细粒度的访问控制，可以留给微服务本身来处理”。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>为了加速“构建-度量-学习”的精益创业循环，业务与IT共同组成的一体化团队不能依赖于集中式的数据团队来获得对业务的洞察。他们需要规划适宜自己的数据流水线，在必要时引入实时数据架构和API，用数据湖来支撑自服务的数据操作，从而更快、更准确地从数据中获得洞察，影响业务决策。更进一步，数据本身也可以作为产品对内部用户乃至外部用户提供服务，并通过细粒度授权体现服务的差异化和安全性需求。通过建设“数据自服务”这个支柱，企业将真正能够盘活数据资产，使其在创新的数字化业务中发挥更大的价值，这是企业数字化旅程的第三步。</p>

      </p>

      <div class="post-list__meta">

        <time datetime="1月 13 2018" class="post-list__meta--date date">1月 13 2018</time> &#8226; 

        <span class="post-list__meta--tags tags">
          <font class="categories">
            
          </font>
          

        </span>
      </div>

      <hr class="post-list__divider" />
    </li>
    
    <li class="post">

      <h2 class="post-list__post-title post-title"><a href="/2018/1/1/2017-readings/" title="link to 2017年读过的好书">2017年读过的好书</a></h2>

      <p class="excerpt">
        <p>今年读了66本书，不过有很大部分是工作需要。而且不知道什么原因，中间读的很多关于内亚性的书都只标了四星……</p>
<h2 id="仅存的内亚性"><a href="#仅存的内亚性" class="headerlink" title="仅存的内亚性"></a>仅存的内亚性</h2><ul>
<li><a href="https://book.douban.com/subject/25883305/" target="_blank" rel="external">阿拉伯的劳伦斯 : 战争、谎言、帝国愚行与现代中东的形成</a> - 一战武器的先进和指挥、情报等其他技术的落后形成一个古怪的组合，让人觉得好多事情都不可理喻。这种对世界充满未知的感觉恐怕未来很多年不会再有了。</li>
</ul>
<h2 id="科技与社会的交集"><a href="#科技与社会的交集" class="headerlink" title="科技与社会的交集"></a>科技与社会的交集</h2><ul>
<li><a href="https://book.douban.com/subject/27021779/" target="_blank" rel="external">智慧转型：重新思考商业模式</a> - 有理论有工具有案例，实在，好用</li>
<li><a href="https://book.douban.com/subject/26916525/" target="_blank" rel="external">Goodbye iSlave : A Manifesto for Digital Abolition</a> - 不仅谈了工厂里的奴隶，还谈到了作为消费者被成瘾性数字产品捆绑而创造无偿内容的另一种奴隶，从而完整展现了数字奴隶制的生态系统。极具洞见，并且只有在中国才能写出。#<a href="https://www.douban.com/update/topic/%E6%95%B0%E5%AD%97%E5%8C%96" target="_blank" rel="external">数字化</a># #<a href="https://www.douban.com/update/topic/%E6%99%BA%E8%83%BD%E8%B5%8B%E6%9D%83" target="_blank" rel="external">智能赋权</a>#</li>
<li><a href="https://book.douban.com/subject/6435517/" target="_blank" rel="external">路易·波拿巴的雾月十八日</a> - 感觉就跟邱林川讲的保守主义回潮有异曲同工之妙，历史第一次是正剧、第二次是闹剧，第三次是什么呢？</li>
</ul>
<h2 id="早就想看的好故事"><a href="#早就想看的好故事" class="headerlink" title="早就想看的好故事"></a>早就想看的好故事</h2><ul>
<li><a href="https://book.douban.com/subject/25796066/" target="_blank" rel="external">恶棍列传</a> - 超级漂亮的小故事，最爱博尔赫斯的故事了</li>
<li><a href="https://book.douban.com/subject/20515828/" target="_blank" rel="external">傅科摆</a> - 太博大了…艾柯编造的神学阴谋论让达芬奇密码就像刺客信条一样直白</li>
<li><a href="https://book.douban.com/subject/26318111/" target="_blank" rel="external">麦田里的守望者</a> - 这才叫中二嘛……我是为素子姐来看塞林格的。</li>
<li><a href="https://book.douban.com/subject/1858513/" target="_blank" rel="external">月亮和六便士</a> - 所谓四十不惑的“不惑”，大概就该是这样的形式吧，知道自己要做什么而不惑于其他，多么令人羡慕。</li>
<li><a href="https://book.douban.com/subject/2035162/" target="_blank" rel="external">刀锋</a> - 求财的得财，求死的得死，求解脱的得解脱，真是一场欢喜大戏。</li>
<li><a href="https://book.douban.com/subject/2165037/" target="_blank" rel="external">荒原狼</a> - 最后终于和荒原狼和解了，这还真是一个美好的故事。</li>
</ul>
<h2 id="比日系推理更好的国产推理"><a href="#比日系推理更好的国产推理" class="headerlink" title="比日系推理更好的国产推理"></a>比日系推理更好的国产推理</h2><ul>
<li><a href="https://book.douban.com/subject/26614581/" target="_blank" rel="external">暗黑者外传：惩罚</a> - 这个故事比欧门尼德系列还好，诡计设置很妙</li>
<li><a href="https://book.douban.com/subject/26923390/" target="_blank" rel="external">长夜难明</a> - 推理其实稍微有点弱，但是故事设置得好，抓人。</li>
<li><a href="https://book.douban.com/subject/26612116/" target="_blank" rel="external">真相推理师：幸存</a> - 这已经甩东野十条街了好吗！瞬间爱上这个作者！（虽然感情戏写得很挫…）</li>
<li><a href="https://book.douban.com/subject/6794021/" target="_blank" rel="external">红手指</a> - 谜题很棒，对人性的描写更是精彩，看完心里堵得慌。</li>
</ul>

      </p>

      <div class="post-list__meta">

        <time datetime="1月 1 2018" class="post-list__meta--date date">1月 1 2018</time> &#8226; 

        <span class="post-list__meta--tags tags">
          <font class="categories">
            
          </font>
          

        </span>
      </div>

      <hr class="post-list__divider" />
    </li>
    
  </ol>

  <hr class="post-list__divider " />

<nav class="pagination" role="navigation">
    

    <span class="pagination__page-number">Page 1 of 1</span>
    
    
</nav>


</div>			
            <footer class="footer">
    <span class="footer__copyright">&copy;
        作者保留一切权利，未经许可请勿转载</span>
    <span class="footer__copyright">&copy;
        2018
        Transparent Thoughts. All rights reserved.</span>
</footer>
        </div>
    </div>

    <!-- The main JavaScript file for Casper -->
    <script src="/js/main.js"></script>
    <script src="/js/scale.fix.js"></script>
    <script src="/js/jquery.imagesloaded.min.js"></script>
    <script src="/js/gallery.js"></script>
    <script src="/js/jquery.githubRepoWidget.min.js"></script>
    <script type="text/javascript"
            src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config"> 
      MathJax.Hub.Config({ 
        tex2jax: {inlineMath: [['[latex]','[/latex]'], ['\\(','\\)']]} 
    }); 

    </script>

    <!--kill ie6 -->
    <!--[if IE 6]>
    <script src="//letskillie6.googlecode.com/svn/trunk/2/zh_CN.js"></script>
    <![endif]-->

    <!-- totop -->
    <div id="totop" style="position:fixed;bottom:50px;right:30px;cursor: pointer;">
        <a title="back to top"><img style="width:30px;height:30px;" src="/images/totop.png"/></a>
    </div>
    <script>
        (function ($) {
            var upperLimit = 100;
            var scrollElem = $('#totop');
            var scrollSpeed = 500;
            scrollElem.hide();
            $(window).scroll(function () {
                var scrollTop = $(document).scrollTop();
                if (scrollTop > upperLimit) {
                    $(scrollElem).stop().fadeTo(300, 1); // fade back in
                } else {
                    $(scrollElem).stop().fadeTo(300, 0); // fade out
                }
            });
            $(scrollElem).click(function () {
                $('html, body').animate({scrollTop: 0}, scrollSpeed);
                return false;
            });
        })(jQuery);
    </script>

    <!-- fancybox -->
    
    <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
    <script src="/fancybox/jquery.fancybox.pack.js"></script>
    <script type="text/javascript">
        (function ($) {
            $('.fancybox').fancybox();
        })(jQuery);
    </script>
    

    <!-- Google Analytics -->
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-113927-4', 'auto');
        ga('send', 'pageview');
    </script>

    <!-- CNZZ Analytics -->
    <script src="http://s4.cnzz.com/z_stat.php?id=1255092465&web_id=1255092465" language="JavaScript"></script>

</body>
</html>
